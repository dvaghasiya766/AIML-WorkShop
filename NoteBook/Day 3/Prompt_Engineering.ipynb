{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# **GenAI: Prompt Engineering**\n",
    "\n",
    "### Dr. Santosh Chapaneri\n",
    "### Lead AI Product Engineer, Wolters Kluwer"
   ],
   "metadata": {
    "id": "pr3-yWvLBc3Z"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install -U langchain langchain_mistralai"
   ],
   "metadata": {
    "id": "hDGeZAk5EX67"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"MISTRAL_API_KEY\"] = \"UV2oAjPsJrHBmTbVZJe5Id50iZEsNyMd\""
   ],
   "metadata": {
    "id": "7oY5UQ-flFRG",
    "ExecuteTime": {
     "end_time": "2026-02-04T04:50:14.239495800Z",
     "start_time": "2026-02-04T04:50:14.220364900Z"
    }
   },
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **LLM**"
   ],
   "metadata": {
    "id": "6SMbIofVEcIj"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain_mistralai import ChatMistralAI\n",
    "\n",
    "llm = ChatMistralAI(\n",
    "    model = 'mistral-small-2506',\n",
    "    temperature = 0\n",
    ")"
   ],
   "metadata": {
    "id": "WzznSgLlEbj7",
    "ExecuteTime": {
     "end_time": "2026-02-04T04:50:15.958978Z",
     "start_time": "2026-02-04T04:50:15.365833400Z"
    }
   },
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **QnA prompt**"
   ],
   "metadata": {
    "id": "v4AjPI1XFcty"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ],
   "metadata": {
    "id": "uedKVHxjF-D4",
    "ExecuteTime": {
     "end_time": "2026-02-04T04:50:16.870871Z",
     "start_time": "2026-02-04T04:50:16.810566800Z"
    }
   },
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "text = \"What is the revalue of TCS in 2025.\"\n",
    "\n",
    "my_template = \"\"\"\n",
    "Answer the question in 3 sentences for a University Student\n",
    "{text}\n",
    "\"\"\"\n",
    "# Give me answer in Symbols\n",
    "\n",
    "prompt = PromptTemplate.from_template(my_template)\n",
    "\n",
    "llm_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "llm_response = llm_chain.invoke({\"text\": text})\n",
    "\n",
    "print(llm_response)"
   ],
   "metadata": {
    "id": "64CSYBo2FDc7",
    "ExecuteTime": {
     "end_time": "2026-02-04T06:08:18.088063500Z",
     "start_time": "2026-02-04T06:08:17.003830100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The revalue of TCS (Tata Consultancy Services) in 2025 is expected to be influenced by factors like market demand, technological advancements, and economic conditions. As a leading IT services company, TCS may see growth due to digital transformation trends and global expansion. However, exact valuation projections require analyzing financial reports, industry trends, and expert forecasts.\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "source": [
    "my_template = \"\"\"\n",
    "Answer the question if it is present in the product title, bullet points or description. \\\n",
    "If question is nonsense, trickery, or has no clear answer, I will respond with \"Unknown\".\n",
    "Start the answer with `A:` with an Explanation\n",
    "\n",
    "Product Title: OnePlus 9R 5G (Carbon Black, 8GB RAM, 128GB Storage)\n",
    "About this item\n",
    "1. Qualcomm Snapdragon 870 5G with upgraded Qualcomm Kryo 585 CPU that performs intense mobile computing at up to 3.2 GHz and also comes with an ultra-fast Qualcomm Adreno 650 GPU for superb on-device experiences\n",
    "2. Loaded with Quad rear camera module that features a 48 MP Main camera, 16 MP Ultra Wide angle Camera, 5 MP Macro camera and a 2 MP Monochrome camera. The device also comes with a 16 MP front Camera\n",
    "3. 6.55 Inches Fluid AMOLED display with 120 Hz of Refresh rate\n",
    "A Powerful 4500 mAh with 65 Watt Warp charging capability\n",
    "4. Oxygen OS based on Andriod 11\n",
    "5. Hands-Free access to Alexa: Alexa on your phone lets you make phone calls, open apps, control smart home devices, access the library of Alexa skills, and more using just your voice while on-the-go. Download the Alexa app and complete hands-free setup to get started. \\\n",
    "Just ask - and Alexa will respond instantly\n",
    "Product Description:\n",
    "6. What's in the box: OnePlus 9R 5G, Power Adapter, Cable, Quick Guide, Welcome Leter, Important Notes, Logo Stickers, Transparent Case, Protector, Card Pin\n",
    "\n",
    "Q: {query}\n",
    "\"\"\"\n",
    "# and output the answer without any explanation.\n",
    "\n",
    "query = \"What is the battery capacity?\"\n",
    "# query = \"Why did Kattapa kill Bahubali?\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(my_template)\n",
    "\n",
    "llm_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "llm_response = llm_chain.invoke({\"query\": query})\n",
    "\n",
    "print(llm_response)"
   ],
   "metadata": {
    "id": "RE0RuHb0FjTa",
    "ExecuteTime": {
     "end_time": "2026-02-04T05:05:27.061891900Z",
     "start_time": "2026-02-04T05:05:26.179861900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: The battery capacity of the OnePlus 9R 5G is 4500 mAh, as mentioned in the product description.\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Summarization**"
   ],
   "metadata": {
    "id": "9oBPtiTRGZQx"
   }
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T05:08:22.707685100Z",
     "start_time": "2026-02-04T05:08:22.688700500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text = \"\"\"\n",
    "Artificial Intelligence and Machine Learning (AIML)\n",
    "\n",
    "Artificial Intelligence (AI) is a branch of computer science that focuses on creating systems capable of performing tasks that normally require human intelligence. These tasks include problem-solving, decision-making, speech recognition, visual perception, and language understanding. Machine Learning (ML) is a subset of AI that enables machines to learn from data and improve their performance without being explicitly programmed.\n",
    "\n",
    "In AIML systems, algorithms analyze large volumes of data to identify patterns and relationships. Based on these patterns, the system can make predictions, classifications, or decisions. Common Machine Learning approaches include supervised learning, unsupervised learning, and reinforcement learning. Supervised learning uses labeled data for training, unsupervised learning discovers hidden patterns in unlabeled data, and reinforcement learning allows agents to learn through trial and error using feedback from the environment.\n",
    "\n",
    "AIML is widely applied across industries such as healthcare, finance, education, e-commerce, and cybersecurity. Examples include disease diagnosis systems, fraud detection models, recommendation engines, autonomous vehicles, and predictive analytics. By automating complex tasks and improving accuracy, AIML helps organizations make data-driven decisions efficiently.\n",
    "\n",
    "Large Language Models (LLMs)\n",
    "\n",
    "Large Language Models (LLMs) are a specialized class of AI models designed to understand, generate, and manipulate human language. They are built using deep learning techniques, particularly transformer-based neural network architectures, and are trained on massive amounts of text data. This large-scale training enables LLMs to learn grammar, context, semantics, and even reasoning patterns in natural language.\n",
    "\n",
    "LLMs can perform a wide range of natural language processing (NLP) tasks such as text generation, translation, summarization, question answering, sentiment analysis, and code generation. Unlike traditional rule-based systems, LLMs generate responses by predicting the most probable next words based on context, making their outputs flexible and human-like.\n",
    "\n",
    "Popular applications of LLMs include virtual assistants, chatbots, customer support systems, content generation tools, and programming assistants. In education and research, LLMs are used to support learning, automate documentation, and assist in knowledge discovery. However, challenges such as data bias, hallucinated outputs, ethical concerns, and computational costs must be addressed for responsible use.\n",
    "\n",
    "Relationship Between AIML and LLMs\n",
    "\n",
    "LLMs are an advanced application of AIML, combining machine learning, deep learning, and natural language processing. While AIML provides the foundational techniques and algorithms, LLMs demonstrate how these techniques can be scaled to handle complex language tasks. Together, AIML and LLMs are transforming how humans interact with machines, enabling more natural, intelligent, and adaptive systems.\n",
    "\"\"\""
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "source": [
    "my_template = f\"\"\"\n",
    "Summarize the following text into a single sentence\n",
    "{text}\n",
    "\"\"\"\n",
    "\n",
    "context = \"\"\"\n",
    "Prompt engineering is a process in natural language processing (NLP) and artificial intelligence (AI) \\\n",
    "that involves designing and optimizing text prompts to elicit specific responses from language models. \\\n",
    "The goal of prompt engineering is to generate high-quality and relevant outputs from language models, \\\n",
    "such as answers to questions or generated text, by carefully crafting the input prompts. \\\n",
    "Prompt engineering has applications in various fields, including language translation, text summarization, \\\n",
    "and chatbots.\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(my_template)\n",
    "\n",
    "llm_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "llm_response = llm_chain.invoke({\"context\": context})\n",
    "\n",
    "print(llm_response)"
   ],
   "metadata": {
    "id": "K7qszIEWGaSJ",
    "ExecuteTime": {
     "end_time": "2026-02-04T05:08:56.090259Z",
     "start_time": "2026-02-04T05:08:55.056342100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Intelligence (AI) and Machine Learning (ML) focus on creating systems that perform human-like tasks, with ML enabling machines to learn from data, while Large Language Models (LLMs), a specialized AI application, use deep learning to understand and generate human language, transforming human-machine interactions through advanced NLP capabilities.\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Text Classification**"
   ],
   "metadata": {
    "id": "2Z6Lh5bhGtUx"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "my_template = \"\"\"\n",
    "Classify the following review into 'neutral', 'negative' or 'positive'.\n",
    "Only output the label in the format 'Label: label' with explanation.\n",
    "Review: {review}\n",
    "\"\"\"\n",
    "\n",
    "review = \"\"\"\n",
    "It‚Äôs firstly not smooth at all. \\\n",
    "Sometimes doesn‚Äôt even work. Buttons. \\\n",
    "When they do, on pressing down button, it goes up and on pressing up button, it goes down. \\\n",
    "Memory button doesn‚Äôt work at all. Quality is definitely not worth the price. Don‚Äôt buy\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(my_template)\n",
    "\n",
    "llm_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "llm_response = llm_chain.invoke({\"review\": review})\n",
    "\n",
    "print(llm_response)"
   ],
   "metadata": {
    "id": "RftDt2OfGuCI",
    "ExecuteTime": {
     "end_time": "2026-02-04T05:12:47.837088800Z",
     "start_time": "2026-02-04T05:12:46.760415300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: negative\n",
      "Explanation: The review contains multiple negative statements about the product's functionality, quality, and value, including phrases like \"not smooth at all,\" \"doesn‚Äôt even work,\" \"doesn‚Äôt work at all,\" and \"quality is definitely not worth the price.\" The final advice, \"Don‚Äôt buy,\" reinforces the negative sentiment.\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "source": [
    "long_review = \"\"\"\n",
    "Short version: Good product, difficult assembly and minor flaws, but still recommend it, especially for WFH üëç.\n",
    "\n",
    "Long version: Been using it for one month now, it is a very good product for work from home and \\\n",
    "even some gaming if you get tired of sitting! The assembly is NOT easy though. \\\n",
    "100% recommend having one person to help, and even then you need to clear your \\\n",
    "entire afternoon to assemble this thing.\n",
    "\n",
    "Assembly especially takes time as the instructions are a little wrong and you need to go back \\\n",
    "and redo some things (in my case they made us install the motor on wrong side of the desk. \\\n",
    "The wire connecting control panel to motor is very short, so both things need to be on same side of the desk. \\\n",
    "But the instructions made us install them on opposite sides. So, had to disassemble a little and \\\n",
    "move the motor to the right side as well - the whole thing probably added 25-30 minutes to the assembly time). \\\n",
    "Other than that though, the instructions were as helpful as they could get, considering the complexity of assembly. \\\n",
    "There is a virtual demo offered as well for assembly, but I did not try it out.\n",
    "\n",
    "However, all the assembly hassle and the price are, in my opinion, well worth it.\n",
    "The desk is excellent, though it does wobble a little when you increase the height,\n",
    "but that's probably because we didn't tighten the screws enough. It is very sturdy, \\\n",
    "there's enough space for anything you might need to put on there (you can see from the image - \\\n",
    "that's two 24 inch monitors and an ATX mid-tower case, and I still have space for my subwoofer, speakers, and\n",
    "probably even a laptop if I wanted to keep one there). The cable management options\n",
    "are nice-to-have but not too helpful.\n",
    "\n",
    "Bottle holder and headphone stand are nice to have as well, unfortunately the headphone stand didn't \\\n",
    "work out for me because it's on the left, the wire will go across the entire desk when I hang them there, \\\n",
    "so I just don't use it.\n",
    "\n",
    "It's only been a month but so far, the motor is working well. I set the sitting and standing preset based \\\n",
    "on my preference and switch between them a few times every day, no complaints there. \\\n",
    "I would estimate there's probably about 20-25 kgs of weight on it right now, but the\\\n",
    "motor adjusts the height effortlessly.\n",
    "\n",
    "One thing that bothers me is that it seems the height is not even from left to right - \\\n",
    "I measured using inch tape and the left side is lower than right side. Hard to notice when \\\n",
    "you're working at the table, but it's there if you look closely enough. The left leg seems to be lower than the \\\n",
    "right - I have added the second image to showcase this.\n",
    "\n",
    "Overall though, these are only very minor flaws and one-time inconveniences, and \\\n",
    "for the value the desk offers, I think it is still an excellent purchase for me at least, \\\n",
    "who needs to be at the desk for almost the entire day, either for work or personal use. \\\n",
    "If you also work from home and get tired of sitting the entire day, I highly recommend this product.\n",
    "\"\"\"\n",
    "\n",
    "my_template = \"\"\"\n",
    "Classify the following review into 'neutral', 'negative' or 'positive'.\n",
    "Only output the label in the format 'Label: label' with explanation.\n",
    "Review: {review}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(my_template)\n",
    "\n",
    "llm_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "llm_response = llm_chain.invoke({\"review\": review})\n",
    "\n",
    "print(llm_response)"
   ],
   "metadata": {
    "id": "UmEaBNUNG6u4",
    "ExecuteTime": {
     "end_time": "2026-02-04T05:16:08.410446400Z",
     "start_time": "2026-02-04T05:16:07.430008Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: negative\n",
      "Explanation: The review contains multiple negative statements about the product's functionality, quality, and value, including phrases like \"not smooth at all,\" \"doesn‚Äôt even work,\" \"doesn‚Äôt work at all,\" and \"quality is definitely not worth the price.\" The final advice, \"Don‚Äôt buy,\" reinforces the negative sentiment.\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "source": [
    "my_template_list = \"\"\"\n",
    "Identify a list of human emotions that the writer of the \\\n",
    "following review is expressing. Include no more than \\\n",
    "five items in the list. Format your answer as a list of \\\n",
    "lower-case words separated by commas.\n",
    "\n",
    "Review text: {review}\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(my_template_list)\n",
    "\n",
    "llm_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "llm_response = llm_chain.invoke({\"review\": long_review})\n",
    "\n",
    "print(llm_response)"
   ],
   "metadata": {
    "id": "P1OHfd8fHHPn",
    "ExecuteTime": {
     "end_time": "2026-02-04T05:18:34.008360800Z",
     "start_time": "2026-02-04T05:18:33.435497700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frustration, satisfaction, annoyance, relief, enthusiasm\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "source": [
    "my_template_single = \"\"\"\n",
    "Is the writer of the following review expressing anger?\n",
    "Only output a single word `Yes` or `No`.\n",
    "Don't provide explanation or reasoning.\n",
    "Review text: {review}\n",
    "Is Customer Frustrated:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(my_template_single)\n",
    "\n",
    "llm_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "llm_response = llm_chain.invoke({\"review\": long_review})\n",
    "\n",
    "print(llm_response)"
   ],
   "metadata": {
    "id": "VudBlxMHHRyf",
    "ExecuteTime": {
     "end_time": "2026-02-04T05:19:11.631296600Z",
     "start_time": "2026-02-04T05:19:11.098672800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Named Entity Recognition**"
   ],
   "metadata": {
    "id": "KJGBQlzNHbBw"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "my_template_ner = \"\"\"\n",
    "Identify the following items from the review text:\n",
    "- Sentiment (positive or negative)\n",
    "- Is the reviewer expressing anger? (true or false)\n",
    "- Item purchased by reviewer\n",
    "- Company that made the item\n",
    "\n",
    "Format your response as a JSON object with \"Sentiment\", \"Anger\", \"Item\"\n",
    "and \"Brand\" as the keys.\n",
    "If the information isn't present, use \"unknown\" as the value.\n",
    "\n",
    "Review text: {review}\n",
    "JSON output:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(my_template_ner)\n",
    "\n",
    "llm_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "llm_response = llm_chain.invoke({\"review\": long_review})\n",
    "\n",
    "print(llm_response)"
   ],
   "metadata": {
    "id": "A3sbfThGHrFo",
    "ExecuteTime": {
     "end_time": "2026-02-04T05:19:41.488621800Z",
     "start_time": "2026-02-04T05:19:40.449000500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"Sentiment\": \"positive\",\n",
      "  \"Anger\": \"false\",\n",
      "  \"Item\": \"desk\",\n",
      "  \"Brand\": \"unknown\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Topic Modeling**"
   ],
   "metadata": {
    "id": "VgB2ELybHxGX"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "blog = \"\"\"\n",
    "In a recent survey conducted by the government,\n",
    "public sector employees were asked to rate their level\n",
    "of satisfaction with the department they work at.\n",
    "The results revealed that NASA was the most popular\n",
    "department with a satisfaction rating of 95%.\n",
    "\n",
    "One NASA employee, John Smith, commented on the findings,\n",
    "stating, \"I'm not surprised that NASA came out on top.\n",
    "It's a great place to work with amazing people and\n",
    "incredible opportunities. I'm proud to be a part of\n",
    "such an innovative organization.\"\n",
    "\n",
    "The results were also welcomed by NASA's management team,\n",
    "with Director Tom Johnson stating, \"We are thrilled to\n",
    "hear that our employees are satisfied with their work at NASA.\n",
    "We have a talented and dedicated team who work tirelessly\n",
    "to achieve our goals, and it's fantastic to see that their\n",
    "hard work is paying off.\"\n",
    "\n",
    "The survey also revealed that the\n",
    "Social Security Administration had the lowest satisfaction\n",
    "rating, with only 45% of employees indicating they were\n",
    "satisfied with their job. The government has pledged to\n",
    "address the concerns raised by employees in the survey and\n",
    "work towards improving job satisfaction across all departments.\n",
    "\"\"\"\n",
    "\n",
    "my_template_tm = \"\"\"\n",
    "Determine whether each item in the following list of \\\n",
    "topics is a topic in the blog below , which\n",
    "is delimited with triple backquotes.\n",
    "\n",
    "List of topics: {topic_list_str}\n",
    "\n",
    "Blog post: {blog}\n",
    "\n",
    "Give your answer as a list with 0 or 1 for each topic.\n",
    "\"\"\"\n",
    "\n",
    "topic_list = [\n",
    "    \"nasa\",\n",
    "    \"local government\",\n",
    "    \"engineering\",\n",
    "    \"employee satisfaction\",\n",
    "    \"federal government\"\n",
    "]\n",
    "topic_list_str = {\", \".join(topic_list)}\n",
    "\n",
    "prompt = PromptTemplate.from_template(my_template_tm)\n",
    "\n",
    "llm_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "llm_response = llm_chain.invoke({\n",
    "    \"blog\": blog,\n",
    "    \"topic_list_str\": topic_list_str,\n",
    "})\n",
    "\n",
    "print(llm_response)"
   ],
   "metadata": {
    "id": "jFZyfOnaHyC4",
    "ExecuteTime": {
     "end_time": "2026-02-04T05:25:00.984215Z",
     "start_time": "2026-02-04T05:24:58.036154800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the evaluation of each topic in the given blog post:\n",
      "\n",
      "1. **NASA**: 1 (The blog post discusses NASA's high employee satisfaction rating and quotes from NASA employees and management.)\n",
      "2. **Local government**: 0 (The blog post does not mention local government.)\n",
      "3. **Engineering**: 0 (The blog post does not mention engineering.)\n",
      "4. **Employee satisfaction**: 1 (The blog post focuses on employee satisfaction ratings across government departments.)\n",
      "5. **Federal government**: 1 (The blog post discusses a survey conducted by the government, which includes federal agencies like NASA and the Social Security Administration.)\n",
      "\n",
      "Final answer: `[1, 0, 0, 1, 1]`\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Special Prompting Techniques**"
   ],
   "metadata": {
    "id": "4c3QuXNwISh_"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Zero-shot Prompting**"
   ],
   "metadata": {
    "id": "b7U8BSpfIVcw"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "All the above example are zero-shot as we haven't given any examples in the context, i.e., zero examples to learn the desired output and nature of task. The model has to solely rely on the user instruction"
   ],
   "metadata": {
    "id": "L6Mg4ks-IXW3"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Few-Shot Prompting**"
   ],
   "metadata": {
    "id": "3lvBjKi6IY-2"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Providing few examples along with the system instruction is called Few-Shot Prompting"
   ],
   "metadata": {
    "id": "eZIUblhgIaju"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "my_template_fs = \"\"\"\n",
    "<child>: Teach me about patience.\n",
    "\n",
    "<grandparent>: The river that carves the deepest valley flows from a modest spring;\n",
    "the grandest symphony originates from a single note;\n",
    "the most intricate tapestry begins with a solitary thread.\n",
    "\n",
    "<child>: {topic}\n",
    "\n",
    "Your task is to answer in a consistent style and complete only the grandparent part.\n",
    "\"\"\"\n",
    "\n",
    "topic = \"Teach me about humility.\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(my_template_fs)\n",
    "\n",
    "llm_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "llm_response = llm_chain.invoke({\"topic\": topic})\n",
    "\n",
    "print(llm_response)"
   ],
   "metadata": {
    "id": "KiW6MOr8Iyx3",
    "ExecuteTime": {
     "end_time": "2026-02-04T05:28:33.549212900Z",
     "start_time": "2026-02-04T05:28:32.092237300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<grandparent>: The tallest tree bows to the wind without complaint;\n",
      "the vast ocean yields to the shore without resistance;\n",
      "the brightest star humbles itself to the endless night.\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Chain-of-Thought Prompting**\n",
    "\n",
    "Enables complex reasoning capabilities through intermediate reasoning steps."
   ],
   "metadata": {
    "id": "q_pS7umkI_hm"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "few_shot_examples = \"\"\"\n",
    "Q: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done,\n",
    "there will be 21 trees. How many trees did the grove workers plant today?\n",
    "A: We start with 15 trees. Later we have 21 trees. The difference must be the number of trees they planted.\n",
    "So, they must have planted 21 - 15 = 6 trees. The answer is 6.\n",
    "\n",
    "Q: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\n",
    "A: There are 3 cars in the parking lot already. 2 more arrive. Now there are 3 + 2 = 5 cars. The answer is 5.\n",
    "\n",
    "Q: Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\n",
    "A: Leah had 32 chocolates and Leah‚Äôs sister had 42. That means there were originally 32 + 42 = 74\n",
    "chocolates. 35 have been eaten. So in total they still have 74 - 35 = 39 chocolates. The answer is 39.\n",
    "\n",
    "Q: Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops\n",
    "did Jason give to Denny?\n",
    "A: Jason had 20 lollipops. Since he only has 12 now, he must have given the rest to Denny. The number of\n",
    "lollipops he has given to Denny must have been 20 - 12 = 8 lollipops. The answer is 8.\n",
    "\n",
    "Q: Shawn has five toys. For Christmas, he got two toys each from his mom and dad. How many toys does\n",
    "he have now?\n",
    "A: He has 5 toys. He got 2 from mom, so after that he has 5 + 2 = 7 toys. Then he got 2 more from dad, so\n",
    "in total he has 7 + 2 = 9 toys. The answer is 9.\n",
    "\n",
    "Q: There were nine computers in the server room. Five more computers were installed each day, from\n",
    "monday to thursday. How many computers are now in the server room?\n",
    "A: There are 4 days from monday to thursday. 5 computers were added each day. That means in total 4 * 5 =\n",
    "20 computers were added. There were 9 computers in the beginning, so now there are 9 + 20 = 29 computers.\n",
    "The answer is 29.\n",
    "\n",
    "Q: Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many\n",
    "golf balls did he have at the end of wednesday?\n",
    "A: Michael initially had 58 balls. He lost 23 on Tuesday, so after that he has 58 - 23 = 35 balls. On\n",
    "Wednesday he lost 2 more so now he has 35 - 2 = 33 balls. The answer is 33.\n",
    "\n",
    "Q: Olivia has $23. She bought five bagels for $3 each. How much money does she have left?\n",
    "A: She bought 5 bagels for $3 each. This means she spent 5\n",
    "\"\"\"\n",
    "\n",
    "my_template = \"\"\"\n",
    "You have been provide with few question-answer pairs displaying the expected output\n",
    "and for you to infer the task patterns. Based on it, output the answer to final questions.\n",
    "\n",
    "{few_shot_examples}\n",
    "\n",
    "Q: {math_query}\n",
    "A:\"\"\"\n",
    "\n",
    "math_query = \"When I was 10 my sister was half my age. Now I‚Äôm 60 how old is my sister?\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(my_template)\n",
    "\n",
    "llm_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "llm_response = llm_chain.invoke({\n",
    "    \"few_shot_examples\": few_shot_examples,\n",
    "    \"math_query\": math_query,\n",
    "})\n",
    "\n",
    "print(llm_response)"
   ],
   "metadata": {
    "id": "R28mvS4EJBPn",
    "ExecuteTime": {
     "end_time": "2026-02-04T05:34:18.107502600Z",
     "start_time": "2026-02-04T05:34:16.774727Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's break this down step by step.\n",
      "\n",
      "1. When you were 10, your sister was half your age, so she was 10 / 2 = 5 years old.\n",
      "2. The age difference between you and your sister is 10 - 5 = 5 years.\n",
      "3. Now that you are 60, your sister's age would be 60 - 5 = 55 years old.\n",
      "\n",
      "The answer is 55.\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Chaining Prompts**"
   ],
   "metadata": {
    "id": "XU-wyt8jJ54E"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "my_template_review = \"\"\"classifiy the review into negative- positive\"\"\"\n",
    "\n",
    "review = \"\"\"\n",
    "Very poor quality solid top provided. It's shaking badly when it's in full height.\n",
    "I don't know if it will last one year.\n",
    "Nobody contacted for installation assistance. The manual provided was also wrong.\n",
    "They just target customers who are looking for cheap product.\n",
    "Better spend some extra money and buy quality Indian brands.\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(my_template_review)\n",
    "\n",
    "llm_chain = prompt | llm | StrOutputParser() # chaining of operation\n",
    "\n",
    "llm_response = llm_chain.invoke({\"review\": query})\n",
    "\n",
    "print(llm_response)"
   ],
   "metadata": {
    "id": "uaH345cTJ6k1",
    "ExecuteTime": {
     "end_time": "2026-02-04T05:40:11.750800400Z",
     "start_time": "2026-02-04T05:40:09.357535200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To classify a review as **negative** or **positive**, you can follow these steps:\n",
      "\n",
      "1. **Analyze the Sentiment**:\n",
      "   - Look for words that express emotions (e.g., \"great,\" \"terrible,\" \"happy,\" \"angry\").\n",
      "   - Check for positive or negative connotations in the review.\n",
      "\n",
      "2. **Check for Key Phrases**:\n",
      "   - **Positive**: \"I loved it,\" \"excellent service,\" \"highly recommend,\" \"worth the money.\"\n",
      "   - **Negative**: \"Waste of time,\" \"poor quality,\" \"disappointed,\" \"never again.\"\n",
      "\n",
      "3. **Consider Tone & Context**:\n",
      "   - Even if a review has some positive words, sarcasm or strong negative phrases can make it overall negative.\n",
      "\n",
      "4. **Use a Sentiment Analysis Tool (Optional)**:\n",
      "   - Tools like **VADER (Valence Aware Dictionary and sEntiment Reasoner)** or **TextBlob** can help automate classification.\n",
      "\n",
      "### Example Classifications:\n",
      "- **\"The product was amazing and exceeded my expectations!\"** ‚Üí **Positive**\n",
      "- **\"Terrible experience, would not buy again.\"** ‚Üí **Negative**\n",
      "- **\"It was okay, but not great.\"** ‚Üí **Neutral** (if you're only classifying as positive/negative)\n",
      "\n",
      "Would you like me to classify a specific review for you?\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "source": [
    "def get_review_sentiment(review):\n",
    "  prompt = PromptTemplate.from_template(my_template_review)\n",
    "\n",
    "  llm_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "  llm_response = llm_chain.invoke({\"review\": review})\n",
    "\n",
    "  return llm_response\n",
    "\n",
    "def is_negative_sentiment(sentiment):\n",
    "    return  \"negative\" in sentiment"
   ],
   "metadata": {
    "id": "ns6faPs5T-WR",
    "ExecuteTime": {
     "end_time": "2026-02-04T05:40:13.045475600Z",
     "start_time": "2026-02-04T05:40:13.027482500Z"
    }
   },
   "outputs": [],
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "source": [
    "email_template = \"\"\"\n",
    "You are a customer service assistant for a large e-commerce store.\n",
    "The customer is unhappy with the product.\n",
    "Send them an email apologizing for the bad experience and mention that the\n",
    "concerned team is looking into the aspects complained by the customer in\n",
    "the review.\n",
    "\n",
    "Review text: {review}\n",
    "Email:\n",
    "\"\"\"\n",
    "\n",
    "if is_negative_sentiment(get_review_sentiment(review)):\n",
    "    email_prompt = PromptTemplate.from_template(email_template)\n",
    "    llm_email_chain = email_prompt | llm | StrOutputParser()\n",
    "    llm_response = llm_email_chain.invoke({\"review\": review})\n",
    "    print(llm_response)"
   ],
   "metadata": {
    "id": "TC7ycKD7KB-W",
    "ExecuteTime": {
     "end_time": "2026-02-04T05:40:18.210249800Z",
     "start_time": "2026-02-04T05:40:14.037902700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Subject:** We‚Äôre Sorry for Your Experience ‚Äì We‚Äôre Looking Into It\n",
      "\n",
      "Dear [Customer's Name],\n",
      "\n",
      "Thank you for taking the time to share your feedback regarding the [Product Name]. We sincerely apologize for the poor quality and the issues you‚Äôve experienced with the solid top, especially the shaking at full height. We understand how frustrating this must be, and we regret that we did not meet your expectations.\n",
      "\n",
      "We take your concerns very seriously, and our team is actively reviewing the aspects you‚Äôve highlighted‚Äîincluding the installation assistance, manual accuracy, and product durability. Your feedback is invaluable in helping us improve our products and services.\n",
      "\n",
      "We‚Äôd like to make this right for you. Please reply to this email with your order details, and we‚Äôll work with you to find a suitable resolution. If you‚Äôd prefer, you can also reach out to our customer support team at [support email/phone number] for immediate assistance.\n",
      "\n",
      "Once again, we apologize for the inconvenience and appreciate your patience as we address these concerns. We hope to regain your trust and provide you with a better experience in the future.\n",
      "\n",
      "Best regards,\n",
      "[Your Name]\n",
      "[Customer Service Team]\n",
      "[E-commerce Store Name]\n",
      "[Contact Information]\n",
      "\n",
      "---\n",
      "*Note: Personalize the email with the customer‚Äôs name, product details, and your store‚Äôs contact information for a more tailored response.*\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Evaluation using LLM**"
   ],
   "metadata": {
    "id": "CCeTrP5ALQ2d"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "blog = \"\"\"\n",
    "Prompt engineering is a process in natural language processing (NLP) and\n",
    "artificial intelligence (AI) that involves designing and optimizing text\n",
    "prompts to elicit specific responses from language models. The goal of prompt\n",
    "engineering is to generate high-quality and relevant outputs from language\n",
    "models, such as answers to questions or generated text, by carefully crafting\n",
    "the input prompts. Prompt engineering has applications in various fields,\n",
    "including language translation, text summarization, and chatbots.\n",
    "\"\"\"\n",
    "\n",
    "summary = \"\"\"\n",
    "Prompt engineering is a process in NLP and AI that involves designing and\n",
    "optimizing text prompts to elicit specific responses from language models.\n",
    "\"\"\"\n",
    "\n",
    "eval_template = \"\"\"\n",
    "You are an assistant that evaluates how well an agent is able to summarize\n",
    "a blog by looking at the blog that the agent is using to generate its summary.\n",
    "\n",
    "You are evaluating a submitted summary to based on the blog.\n",
    "Here is the data:\n",
    "    [BEGIN DATA]\n",
    "    ************\n",
    "    [BLOG]: {blog}\n",
    "    ************\n",
    "    [SUMMARY]: {summary}\n",
    "    ************\n",
    "    [END DATA]\n",
    "\n",
    "Compare the factual content of the submitted summary with the blog.\n",
    "Ignore any differences in style, grammar, or punctuation.\n",
    "\n",
    "Answer the following questions:\n",
    "    - Is the summary based only on the Blog provided? (Y or N)\n",
    "    - Does the summary include information that is not provided in the blog? (Y or N)\n",
    "    - Is there any disagreement between the summary and the blog? (Y or N)\n",
    "\n",
    "Once you have answers to the above questions, convert the output to JSON object with following keys:\n",
    "\"Grounded Summary\", \"Excess Information\" and \"Mismatched Information\". The values are (Y or N).\n",
    "\n",
    "Output:\n",
    "\"\"\"\n",
    "\n",
    "eval_prompt = PromptTemplate.from_template(eval_template)\n",
    "\n",
    "llm_eval_chain = eval_prompt | llm | StrOutputParser()\n",
    "\n",
    "llm_response = llm_eval_chain.invoke({\n",
    "    \"blog\": blog,\n",
    "    \"summary\": summary\n",
    "})\n",
    "\n",
    "print(llm_response)"
   ],
   "metadata": {
    "id": "d9u3sykFLRbs",
    "ExecuteTime": {
     "end_time": "2026-02-04T05:49:03.462596900Z",
     "start_time": "2026-02-04T05:49:02.616950700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"Grounded Summary\": \"Y\",\n",
      "  \"Excess Information\": \"N\",\n",
      "  \"Mismatched Information\": \"N\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "authorship_tag": "ABX9TyMIJjDdWV0f0PPwNx25IEdB"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
